{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#65AE11;\">Kernel Launches in Non-Default Streams</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will learn to launch kernels in non-default streams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Objectives</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the time you complete this section you will:\n",
    "\n",
    "* Know how to create non-default streams\n",
    "* Be able to launch kernels in non-default streams\n",
    "* Know how to observe operations in non-default streams in Nsight Systems\n",
    "* Know how to destroy non-default streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Non-Default Stream Creation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a new non-default stream, pass `cudaStreamCreate` a `cudaStream_t` pointer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "cudaStream_t stream;\n",
    "cudaStreamCreate(&stream);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Launching a Kernel in a Non-Default Stream</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To launch a kernel in a non-default stream, pass a non-default stream identifier as its 4th launch configuration argument. Because a kernel's 3rd launch configuration argument defines dynamically allocated shared memory, you will need to pass it `0` (its default value since we are not using shared memory) if you are not modifying its default value:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "cudaStream_t stream;\n",
    "cudaStreamCreate(&stream);\n",
    "\n",
    "kernel<<<grid, blocks, 0, stream>>>();\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Non-Default Stream Destruction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Destroy non-default streams when you are done with them by passing a non-default stream identifier to `cudaStreamDestroy`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "cudaStream_t stream;\n",
    "cudaStreamCreate(&stream);\n",
    "\n",
    "kernel<<<grid, blocks, 0, stream>>>();\n",
    "\n",
    "cudaStreamDestroy(stream);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Exercise: Launch Kernel in Non-Default Stream</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open and refactor [*06_Kernels_in_Streams/baseline_cipher/baseline.cu*](baseline_cipher/baseline.cu) to launch the `decrypt_gpu` kernel (around line 65) in a non-default stream.\n",
    "\n",
    "Generate a report file for the refactored application by using a JupyterLab terminal and running `make profile` from within the *06_Kernels_in_Streams/baseline_cipher* directory. (See the [*Makefile*](baseline_cipher/Makefile) there for details).\n",
    "\n",
    "Open the report file in Nsight Systems. If you've closed the Nsight Systems tab, you can reopen it by following the instructions in [*Nsight Systems Setup*](../04_Nsight_Systems_Setup/Nsight_Systems_Setup.ipynb). As a reminder the password is `nvidia`.\n",
    "\n",
    "If you were successful, you should notice that the Nsight Systems visual timeline is now presenting information about streams, and that the kernel launch occured in some non-default stream, as is shown in the screenshot below.\n",
    "\n",
    "If you get stuck, please refer to [06_Kernels_in_Streams/baseline_cipher/baseline_solution.cu](../06_Kernels_in_Streams/baseline_cipher/baseline_solution.cu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/home/scortinhal/CHPS0904/task/06_Kernels_in_Streams\n",
      "TIMING: 25.7353 ms (allocate memory)\n",
      "TIMING: 14758.2 ms (encrypt data on CPU)\n",
      "TIMING: 1.95904 ms (copy data from CPU to GPU)\n",
      "TIMING: 33.6227 ms (decrypt data on GPU)\n",
      "TIMING: 3.16995 ms (copy data from GPU to CPU)\n",
      "TIMING: 38.8173 ms (total time on GPU)\n",
      "STATUS: test passed\n",
      "TIMING: 4.65728 ms (checking result on CPU)\n",
      "TIMING: 7.35942 ms (free memory)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Affiche le répertoire courant pour vérifier le point de départ\n",
    "pwd\n",
    "\n",
    "cd baseline_cipher\n",
    "\n",
    "module load cuda/12.6\n",
    "\n",
    "\n",
    "./baseline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ma version exercice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/home/scortinhal/CHPS0904/task/06_Kernels_in_Streams\n",
      "nvcc -arch=sm_70 -O3 -Xcompiler=\"-march=native -fopenmp\" baseline.cu -o baseline\n",
      "nsys profile --stats=true --force-overwrite=true -o baseline-report ./baseline\n",
      "TIMING: 25.2567 ms (allocate memory)\n",
      "TIMING: 15792.8 ms (encrypt data on CPU)\n",
      "TIMING: 1.91565 ms (copy data from CPU to GPU)\n",
      "TIMING: 33.8669 ms (decrypt data on GPU)\n",
      "TIMING: 3.17808 ms (copy data from GPU to CPU)\n",
      "TIMING: 39.0371 ms (total time on GPU)\n",
      "STATUS: test passed\n",
      "TIMING: 4.77162 ms (checking result on CPU)\n",
      "TIMING: 11.2442 ms (free memory)\n",
      "TIMING: 15873.3 ms (Temps total)\n",
      "Collecting data...\n",
      "Generating '/tmp/nsys-report-ea7a.qdstrm'\n",
      "[1/8] [========================100%] baseline-report.nsys-rep\n",
      "[2/8] [========================100%] baseline-report.sqlite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SKIPPED: /gpfs/home/scortinhal/CHPS0904/task/06_Kernels_in_Streams/kernel_baseline_cipher/baseline-report.sqlite does not contain NV Tools Extension (NVTX) data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/8] Executing 'nvtx_sum' stats report\n",
      "[4/8] Executing 'osrt_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls   Avg (ns)     Med (ns)    Min (ns)   Max (ns)   StdDev (ns)           Name         \n",
      " --------  ---------------  ---------  -----------  -----------  --------  ----------  -----------  ----------------------\n",
      "     50.0      16177260160        171   94603860.6  100114656.0      1312   158001824   23109822.3  poll                  \n",
      "     49.1      15881414976         63  252085952.0    4543712.0     31264  1040811488  430823779.7  futex                 \n",
      "      0.9        288095040        850     338935.3      12896.0      1024    83205280    3092574.8  ioctl                 \n",
      "      0.0          6273600         17     369035.3     354688.0    341568      517888      41695.1  pthread_create        \n",
      "      0.0          5694688         38     149860.2      10608.0      2080     5263136     851919.4  mmap                  \n",
      "      0.0           722176         81       8915.8       5568.0      2688      127744      14658.8  fopen                 \n",
      "      0.0           611680         48      12743.3      12000.0      4800       25216       3935.2  mmap64                \n",
      "      0.0           378016         76       4973.9       4608.0      1056       10848       1752.9  open64                \n",
      "      0.0           336064         10      33606.4      24256.0     17600      121600      31215.4  sem_timedwait         \n",
      "      0.0           177280         38       4665.3       1632.0      1056       89216      14266.1  fclose                \n",
      "      0.0            93056          1      93056.0      93056.0     93056       93056          0.0  pthread_cond_wait     \n",
      "      0.0            73408          5      14681.6       4256.0      3072       52224      21174.4  fgets                 \n",
      "      0.0            70016          4      17504.0      11728.0      9664       36896      12967.5  fread                 \n",
      "      0.0            53216          9       5912.9       5728.0      1632       13792       3855.9  open                  \n",
      "      0.0            52928         11       4811.6       4992.0      1344       11040       3181.0  fflush                \n",
      "      0.0            41024          4      10256.0       3104.0      1056       33760      15743.0  fcntl                 \n",
      "      0.0            32192         11       2926.5       2752.0      1920        3904        701.6  write                 \n",
      "      0.0            29600          6       4933.3       5552.0      1376        7264       2027.0  munmap                \n",
      "      0.0            27840          4       6960.0       4192.0      3904       15552       5729.8  fopen64               \n",
      "      0.0            24544          9       2727.1       1472.0      1024        7328       2168.4  read                  \n",
      "      0.0            22528          3       7509.3       7776.0      2464       12288       4917.4  pipe2                 \n",
      "      0.0            18144          2       9072.0       9072.0      5568       12576       4955.4  socket                \n",
      "      0.0            12608          1      12608.0      12608.0     12608       12608          0.0  connect               \n",
      "      0.0            11776          4       2944.0       2672.0      1152        5280       1732.1  fwrite                \n",
      "      0.0             3168          1       3168.0       3168.0      3168        3168          0.0  pthread_cond_broadcast\n",
      "      0.0             2816          1       2816.0       2816.0      2816        2816          0.0  bind                  \n",
      "      0.0             1376          1       1376.0       1376.0      1376        1376          0.0  putc                  \n",
      "\n",
      "[5/8] Executing 'cuda_api_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls   Avg (ns)    Med (ns)   Min (ns)  Max (ns)  StdDev (ns)           Name         \n",
      " --------  ---------------  ---------  ----------  ----------  --------  --------  -----------  ----------------------\n",
      "     43.7         33081856          1  33081856.0  33081856.0  33081856  33081856          0.0  cudaStreamSynchronize \n",
      "     31.8         24025792          1  24025792.0  24025792.0  24025792  24025792          0.0  cudaHostAlloc         \n",
      "     13.6         10254208          1  10254208.0  10254208.0  10254208  10254208          0.0  cudaFreeHost          \n",
      "      6.7          5083584          2   2541792.0   2541792.0   1909152   3174432     894688.1  cudaMemcpy            \n",
      "      1.6          1207296          1   1207296.0   1207296.0   1207296   1207296          0.0  cudaMalloc            \n",
      "      1.3           979840          1    979840.0    979840.0    979840    979840          0.0  cudaFree              \n",
      "      0.9           704992          1    704992.0    704992.0    704992    704992          0.0  cudaLaunchKernel      \n",
      "      0.2           125088         18      6949.3      3104.0      1760     42816       9981.1  cudaEventRecord       \n",
      "      0.1            78560          9      8728.9      6944.0      5760     22144       5098.8  cudaEventSynchronize  \n",
      "      0.1            50176          1     50176.0     50176.0     50176     50176          0.0  cudaStreamCreate      \n",
      "      0.0            17248          1     17248.0     17248.0     17248     17248          0.0  cudaStreamDestroy     \n",
      "      0.0            10592          6      1765.3       544.0       416      7968       3040.8  cudaEventCreate       \n",
      "      0.0             2560          6       426.7       240.0       192      1024        346.8  cudaEventDestroy      \n",
      "      0.0             2240          1      2240.0      2240.0      2240      2240          0.0  cuModuleGetLoadingMode\n",
      "\n",
      "[6/8] Executing 'cuda_gpu_kern_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances   Avg (ns)    Med (ns)   Min (ns)  Max (ns)  StdDev (ns)                             Name                           \n",
      " --------  ---------------  ---------  ----------  ----------  --------  --------  -----------  ----------------------------------------------------------\n",
      "    100.0         33077056          1  33077056.0  33077056.0  33077056  33077056          0.0  decrypt_gpu(unsigned long *, unsigned long, unsigned long)\n",
      "\n",
      "[7/8] Executing 'cuda_gpu_mem_time_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Count  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)           Operation          \n",
      " --------  ---------------  -----  ---------  ---------  --------  --------  -----------  ----------------------------\n",
      "     63.7          3152800      1  3152800.0  3152800.0   3152800   3152800          0.0  [CUDA memcpy Device-to-Host]\n",
      "     36.3          1793888      1  1793888.0  1793888.0   1793888   1793888          0.0  [CUDA memcpy Host-to-Device]\n",
      "\n",
      "[8/8] Executing 'cuda_gpu_mem_size_sum' stats report\n",
      "\n",
      " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)           Operation          \n",
      " ----------  -----  --------  --------  --------  --------  -----------  ----------------------------\n",
      "    536.871      1   536.871   536.871   536.871   536.871        0.000  [CUDA memcpy Device-to-Host]\n",
      "    536.871      1   536.871   536.871   536.871   536.871        0.000  [CUDA memcpy Host-to-Device]\n",
      "\n",
      "Generated:\n",
      "    /gpfs/home/scortinhal/CHPS0904/task/06_Kernels_in_Streams/kernel_baseline_cipher/baseline-report.nsys-rep\n",
      "    /gpfs/home/scortinhal/CHPS0904/task/06_Kernels_in_Streams/kernel_baseline_cipher/baseline-report.sqlite\n",
      "TIMING: 26.0389 ms (allocate memory)\n",
      "TIMING: 14828.2 ms (encrypt data on CPU)\n",
      "TIMING: 2.06042 ms (copy data from CPU to GPU)\n",
      "TIMING: 34.1583 ms (decrypt data on GPU)\n",
      "TIMING: 3.17955 ms (copy data from GPU to CPU)\n",
      "TIMING: 39.4702 ms (total time on GPU)\n",
      "STATUS: test passed\n",
      "TIMING: 4.69392 ms (checking result on CPU)\n",
      "TIMING: 11.4702 ms (free memory)\n",
      "TIMING: 14910.1 ms (Temps total)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Affiche le répertoire courant pour vérifier le point de départ\n",
    "pwd\n",
    "\n",
    "cd kernel_baseline_cipher\n",
    "\n",
    "module load cuda/12.6\n",
    "\n",
    "make profile\n",
    "\n",
    "./baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kernel_in_stream](images/kernel_in_stream.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Next</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you can launch kernels in non-default streams, you will in the next section launch memory transfers in non-default streams.\n",
    "\n",
    "Please continue to the next section: [*Memcpy in Streams*](../07_Memcpy_in_Streams/Memcpy_in_Streams.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Optional Further Study</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are for students with time and interest to do additional study on topics related to this workshop.\n",
    "\n",
    "* In scenarios where a single kernel is unable to saturate the device, you might consider using streams to [launch multiple kernels simultaneously](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#concurrent-kernel-execution).\n",
    "* For full coverage of of CUDA stream management functions, see [Stream Management](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html) in the CUDA Runtime API docs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
