{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#65AE11;\">Kernel Launches in Non-Default Streams</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will learn to launch kernels in non-default streams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Objectives</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the time you complete this section you will:\n",
    "\n",
    "* Know how to create non-default streams\n",
    "* Be able to launch kernels in non-default streams\n",
    "* Know how to observe operations in non-default streams in Nsight Systems\n",
    "* Know how to destroy non-default streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Non-Default Stream Creation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a new non-default stream, pass `cudaStreamCreate` a `cudaStream_t` pointer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "cudaStream_t stream;\n",
    "cudaStreamCreate(&stream);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Launching a Kernel in a Non-Default Stream</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To launch a kernel in a non-default stream, pass a non-default stream identifier as its 4th launch configuration argument. Because a kernel's 3rd launch configuration argument defines dynamically allocated shared memory, you will need to pass it `0` (its default value since we are not using shared memory) if you are not modifying its default value:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "cudaStream_t stream;\n",
    "cudaStreamCreate(&stream);\n",
    "\n",
    "kernel<<<grid, blocks, 0, stream>>>();\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Non-Default Stream Destruction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Destroy non-default streams when you are done with them by passing a non-default stream identifier to `cudaStreamDestroy`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "cudaStream_t stream;\n",
    "cudaStreamCreate(&stream);\n",
    "\n",
    "kernel<<<grid, blocks, 0, stream>>>();\n",
    "\n",
    "cudaStreamDestroy(stream);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Exercise: Launch Kernel in Non-Default Stream</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open and refactor [*06_Kernels_in_Streams/baseline_cipher/baseline.cu*](baseline_cipher/baseline.cu) to launch the `decrypt_gpu` kernel (around line 65) in a non-default stream.\n",
    "\n",
    "Generate a report file for the refactored application by using a JupyterLab terminal and running `make profile` from within the *06_Kernels_in_Streams/baseline_cipher* directory. (See the [*Makefile*](baseline_cipher/Makefile) there for details).\n",
    "\n",
    "Open the report file in Nsight Systems. If you've closed the Nsight Systems tab, you can reopen it by following the instructions in [*Nsight Systems Setup*](../04_Nsight_Systems_Setup/Nsight_Systems_Setup.ipynb). As a reminder the password is `nvidia`.\n",
    "\n",
    "If you were successful, you should notice that the Nsight Systems visual timeline is now presenting information about streams, and that the kernel launch occured in some non-default stream, as is shown in the screenshot below.\n",
    "\n",
    "If you get stuck, please refer to [06_Kernels_in_Streams/baseline_cipher/baseline_solution.cu](../06_Kernels_in_Streams/baseline_cipher/baseline_solution.cu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/home/scortinhal/CHPS0904/task/06_Kernels_in_Streams\n",
      "nsys profile --stats=true --force-overwrite=true -o baseline-report ./baseline\n",
      "TIMING: 37.884 ms (allocate memory)\n",
      "TIMING: 433124 ms (encrypt data on CPU)\n",
      "TIMING: 1.46874 ms (copy data from CPU to GPU)\n",
      "TIMING: 64.5848 ms (decrypt data on GPU)\n",
      "TIMING: 3.47162 ms (copy data from GPU to CPU)\n",
      "TIMING: 74.7554 ms (total time on GPU)\n",
      "STATUS: test passed\n",
      "TIMING: 56.2705 ms (checking result on CPU)\n",
      "TIMING: 11.8645 ms (free memory)\n",
      "Collecting data...\n",
      "Generating '/tmp/nsys-report-31e5.qdstrm'\n",
      "[1/8] [========================100%] baseline-report.nsys-rep\n",
      "[2/8] [========================100%] baseline-report.sqlite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SKIPPED: /gpfs/home/scortinhal/CHPS0904/task/06_Kernels_in_Streams/baseline_cipher/baseline-report.sqlite does not contain NV Tools Extension (NVTX) data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/8] Executing 'nvtx_sum' stats report\n",
      "[4/8] Executing 'osrt_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls   Avg (ns)    Med (ns)    Min (ns)  Max (ns)   StdDev (ns)           Name         \n",
      " --------  ---------------  ---------  ----------  -----------  --------  ---------  -----------  ----------------------\n",
      "     99.9     433516480672       4337  99957685.2  100116096.0      1920  176350112    4891513.3  poll                  \n",
      "      0.1        336261024        768    437839.9      29504.0      1024   35197376    2249517.3  ioctl                 \n",
      "      0.0         24810304          4   6202576.0      32016.0      7968   24738304   12357164.9  fread                 \n",
      "      0.0         20854912          1  20854912.0   20854912.0  20854912   20854912          0.0  pthread_cond_wait     \n",
      "      0.0         15854112          9   1761568.0    1468544.0   1385760    2858208     523644.8  fflush                \n",
      "      0.0          7348096         37    198597.2      14848.0      6720    6746720    1106430.2  mmap                  \n",
      "      0.0          5343648         74     72211.5       6688.0      2496    2634304     380726.1  fopen                 \n",
      "      0.0          5237760         12    436480.0      36784.0      1376    3646528    1040246.5  write                 \n",
      "      0.0          1185216         46     25765.6      16080.0      7232     393408      55652.7  mmap64                \n",
      "      0.0          1129632         12     94136.0       1232.0      1056     835552     245403.6  fcntl                 \n",
      "      0.0           995200          2    497600.0     497600.0    487520     507680      14255.3  pthread_create        \n",
      "      0.0           680736         71      9587.8       7936.0      1280     132416      15165.7  open64                \n",
      "      0.0           205728         34      6050.8       1648.0      1216     102464      17417.6  fclose                \n",
      "      0.0           109632          5     21926.4       7488.0      6176      74560      29622.5  fgets                 \n",
      "      0.0            74656          9      8295.1       7776.0      1664      19872       5747.5  open                  \n",
      "      0.0            51104         16      3194.0       1936.0      1024      10656       2999.1  read                  \n",
      "      0.0            50336          6      8389.3       9632.0      2208      12192       3857.5  munmap                \n",
      "      0.0            32928          2     16464.0      16464.0      9792      23136       9435.6  socket                \n",
      "      0.0            28512          3      9504.0      10496.0      3264      14752       5807.9  pipe2                 \n",
      "      0.0            20384          3      6794.7       4160.0      2400      13824       6150.9  fwrite                \n",
      "      0.0            17952          4      4488.0       2992.0      2656       9312       3222.0  fopen64               \n",
      "      0.0            16928          1     16928.0      16928.0     16928      16928          0.0  connect               \n",
      "      0.0             6720          1      6720.0       6720.0      6720       6720          0.0  pthread_cond_broadcast\n",
      "      0.0             4352          1      4352.0       4352.0      4352       4352          0.0  bind                  \n",
      "      0.0             2496          2      1248.0       1248.0      1152       1344        135.8  futex                 \n",
      "      0.0             1024          1      1024.0       1024.0      1024       1024          0.0  listen                \n",
      "\n",
      "[5/8] Executing 'cuda_api_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls   Avg (ns)    Med (ns)   Min (ns)  Max (ns)  StdDev (ns)           Name         \n",
      " --------  ---------------  ---------  ----------  ----------  --------  --------  -----------  ----------------------\n",
      "     29.6         35354784          1  35354784.0  35354784.0  35354784  35354784          0.0  cudaHostAlloc         \n",
      "     27.7         33120000          8   4140000.0      6544.0      5184  33070816   11689815.1  cudaEventSynchronize  \n",
      "     26.4         31511936          1  31511936.0  31511936.0  31511936  31511936          0.0  cudaLaunchKernel      \n",
      "      8.2          9848352          1   9848352.0   9848352.0   9848352   9848352          0.0  cudaFreeHost          \n",
      "      4.1          4925024          2   2462512.0   2462512.0   1463296   3461728    1413104.8  cudaMemcpy            \n",
      "      2.1          2480352          1   2480352.0   2480352.0   2480352   2480352          0.0  cudaMalloc            \n",
      "      1.7          1999616          1   1999616.0   1999616.0   1999616   1999616          0.0  cudaFree              \n",
      "      0.2           189664         16     11854.0      9168.0      2496     38144       9674.7  cudaEventRecord       \n",
      "      0.0            11072          4      2768.0       800.0       640      8832       4043.5  cudaEventCreate       \n",
      "      0.0             6144          4      1536.0       752.0       384      4256       1832.1  cudaEventDestroy      \n",
      "      0.0             1344          1      1344.0      1344.0      1344      1344          0.0  cuModuleGetLoadingMode\n",
      "\n",
      "[6/8] Executing 'cuda_gpu_kern_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances   Avg (ns)    Med (ns)   Min (ns)  Max (ns)  StdDev (ns)                             Name                           \n",
      " --------  ---------------  ---------  ----------  ----------  --------  --------  -----------  ----------------------------------------------------------\n",
      "    100.0         33072448          1  33072448.0  33072448.0  33072448  33072448          0.0  decrypt_gpu(unsigned long *, unsigned long, unsigned long)\n",
      "\n",
      "[7/8] Executing 'cuda_gpu_mem_time_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Count  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)           Operation          \n",
      " --------  ---------------  -----  ---------  ---------  --------  --------  -----------  ----------------------------\n",
      "     71.2          3431744      1  3431744.0  3431744.0   3431744   3431744          0.0  [CUDA memcpy Device-to-Host]\n",
      "     28.8          1391360      1  1391360.0  1391360.0   1391360   1391360          0.0  [CUDA memcpy Host-to-Device]\n",
      "\n",
      "[8/8] Executing 'cuda_gpu_mem_size_sum' stats report\n",
      "\n",
      " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)           Operation          \n",
      " ----------  -----  --------  --------  --------  --------  -----------  ----------------------------\n",
      "    536.871      1   536.871   536.871   536.871   536.871        0.000  [CUDA memcpy Device-to-Host]\n",
      "    536.871      1   536.871   536.871   536.871   536.871        0.000  [CUDA memcpy Host-to-Device]\n",
      "\n",
      "Generated:\n",
      "    /gpfs/home/scortinhal/CHPS0904/task/06_Kernels_in_Streams/baseline_cipher/baseline-report.nsys-rep\n",
      "    /gpfs/home/scortinhal/CHPS0904/task/06_Kernels_in_Streams/baseline_cipher/baseline-report.sqlite\n",
      "TIMING: 38.4333 ms (allocate memory)\n",
      "Error while terminating subprocess (pid=1675125): \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Affiche le répertoire courant pour vérifier le point de départ\n",
    "pwd\n",
    "\n",
    "cd baseline_cipher\n",
    "\n",
    "module load cuda/12.6\n",
    "\n",
    "make profile\n",
    "\n",
    "./baseline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kernel_in_stream](images/kernel_in_stream.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/home/scortinhal/CHPS0904/task/06_Kernels_in_Streams\n",
      "nsys profile --stats=true --force-overwrite=true -o baseline-report ./baseline\n",
      "TIMING: 40.3016 ms (allocate memory)\n",
      "TIMING: 433275 ms (encrypt data on CPU)\n",
      "TIMING: 1.46723 ms (copy data from CPU to GPU)\n",
      "TIMING: 35.321 ms (decrypt data on GPU)\n",
      "TIMING: 3.47434 ms (copy data from GPU to CPU)\n",
      "TIMING: 44.8525 ms (total time on GPU)\n",
      "STATUS: test passed\n",
      "TIMING: 56.906 ms (checking result on CPU)\n",
      "TIMING: 10.1205 ms (free memory)\n",
      "Collecting data...\n",
      "Generating '/tmp/nsys-report-6d62.qdstrm'\n",
      "[1/8] [========================100%] baseline-report.nsys-rep\n",
      "[2/8] [========================100%] baseline-report.sqlite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SKIPPED: /gpfs/home/scortinhal/CHPS0904/task/06_Kernels_in_Streams/kernel_baseline_cipher/baseline-report.sqlite does not contain NV Tools Extension (NVTX) data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/8] Executing 'nvtx_sum' stats report\n",
      "[4/8] Executing 'osrt_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls   Avg (ns)    Med (ns)    Min (ns)  Max (ns)   StdDev (ns)           Name         \n",
      " --------  ---------------  ---------  ----------  -----------  --------  ---------  -----------  ----------------------\n",
      "     99.9     433740902272       4339  99963333.1  100116768.0      2016  173509312    4887850.3  poll                  \n",
      "      0.1        393957440        770    511633.0      27824.0      1024   37691968    2715625.2  ioctl                 \n",
      "      0.0         15389824          9   1709980.4    1509312.0   1309984    2614368     488999.1  fflush                \n",
      "      0.0          8830976          1   8830976.0    8830976.0   8830976    8830976          0.0  pthread_cond_broadcast\n",
      "      0.0          6689920         37    180808.6      15744.0      5728    6063872     994059.3  mmap                  \n",
      "      0.0          1084736          2    542368.0     542368.0    519904     564832      31768.9  pthread_create        \n",
      "      0.0           866880         46     18845.2      18112.0      6912      36608       5241.9  mmap64                \n",
      "      0.0           797696         74     10779.7       6992.0      2464     135744      16902.8  fopen                 \n",
      "      0.0           778016         11     70728.7      38400.0     23840     291360      81556.4  write                 \n",
      "      0.0           613952         71      8647.2       8384.0      1184      17696       4000.2  open64                \n",
      "      0.0           208640         41      5088.8       1600.0      1152     106368      16447.0  fclose                \n",
      "      0.0           124544          5     24908.8       6528.0      4416      93312      38447.8  fgets                 \n",
      "      0.0           105888          4     26472.0      20352.0     12320      52864      18225.5  fread                 \n",
      "      0.0            98240          1     98240.0      98240.0     98240      98240          0.0  pthread_cond_wait     \n",
      "      0.0            69728         14      4980.6       1184.0      1024      48032      12495.7  fcntl                 \n",
      "      0.0            64640          9      7182.2       6304.0      1728      17984       4925.5  open                  \n",
      "      0.0            51136         16      3196.0       1536.0      1120      12928       3330.8  read                  \n",
      "      0.0            44192          6      7365.3       8976.0      2240       9536       2996.6  munmap                \n",
      "      0.0            28608          3      9536.0       9952.0      3520      15136       5819.2  pipe2                 \n",
      "      0.0            25600          2     12800.0      12800.0      8864      16736       5566.3  socket                \n",
      "      0.0            21600          4      5400.0       2752.0      1024      15072       6509.5  fwrite                \n",
      "      0.0            17664          4      4416.0       2896.0      2592       9280       3246.5  fopen64               \n",
      "      0.0            15584          1     15584.0      15584.0     15584      15584          0.0  connect               \n",
      "      0.0             6240          2      3120.0       3120.0      3104       3136         22.6  futex                 \n",
      "      0.0             3296          1      3296.0       3296.0      3296       3296          0.0  bind                  \n",
      "      0.0             1248          1      1248.0       1248.0      1248       1248          0.0  listen                \n",
      "\n",
      "[5/8] Executing 'cuda_api_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls   Avg (ns)    Med (ns)   Min (ns)  Max (ns)  StdDev (ns)           Name         \n",
      " --------  ---------------  ---------  ----------  ----------  --------  --------  -----------  ----------------------\n",
      "     41.6         37824032          1  37824032.0  37824032.0  37824032  37824032          0.0  cudaHostAlloc         \n",
      "     36.4         33085760          1  33085760.0  33085760.0  33085760  33085760          0.0  cudaStreamSynchronize \n",
      "     10.1          9200992          1   9200992.0   9200992.0   9200992   9200992          0.0  cudaFreeHost          \n",
      "      5.4          4923648          2   2461824.0   2461824.0   1460928   3462720    1415480.7  cudaMemcpy            \n",
      "      2.7          2441504          1   2441504.0   2441504.0   2441504   2441504          0.0  cudaMalloc            \n",
      "      1.6          1465600          1   1465600.0   1465600.0   1465600   1465600          0.0  cudaStreamCreate      \n",
      "      1.0           903264          1    903264.0    903264.0    903264    903264          0.0  cudaFree              \n",
      "      0.8           729664          1    729664.0    729664.0    729664    729664          0.0  cudaLaunchKernel      \n",
      "      0.2           184672         16     11542.0      9312.0      2464     37536       8219.6  cudaEventRecord       \n",
      "      0.1            51200          8      6400.0      5920.0      4512      9984       1841.2  cudaEventSynchronize  \n",
      "      0.0            20960          1     20960.0     20960.0     20960     20960          0.0  cudaStreamDestroy     \n",
      "      0.0            10208          4      2552.0       688.0       480      8352       3868.5  cudaEventCreate       \n",
      "      0.0             5312          4      1328.0       736.0       416      3424       1417.3  cudaEventDestroy      \n",
      "      0.0              992          1       992.0       992.0       992       992          0.0  cuModuleGetLoadingMode\n",
      "\n",
      "[6/8] Executing 'cuda_gpu_kern_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances   Avg (ns)    Med (ns)   Min (ns)  Max (ns)  StdDev (ns)                             Name                           \n",
      " --------  ---------------  ---------  ----------  ----------  --------  --------  -----------  ----------------------------------------------------------\n",
      "    100.0         33080512          1  33080512.0  33080512.0  33080512  33080512          0.0  decrypt_gpu(unsigned long *, unsigned long, unsigned long)\n",
      "\n",
      "[7/8] Executing 'cuda_gpu_mem_time_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Count  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)           Operation          \n",
      " --------  ---------------  -----  ---------  ---------  --------  --------  -----------  ----------------------------\n",
      "     71.2          3433568      1  3433568.0  3433568.0   3433568   3433568          0.0  [CUDA memcpy Device-to-Host]\n",
      "     28.8          1388320      1  1388320.0  1388320.0   1388320   1388320          0.0  [CUDA memcpy Host-to-Device]\n",
      "\n",
      "[8/8] Executing 'cuda_gpu_mem_size_sum' stats report\n",
      "\n",
      " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)           Operation          \n",
      " ----------  -----  --------  --------  --------  --------  -----------  ----------------------------\n",
      "    536.871      1   536.871   536.871   536.871   536.871        0.000  [CUDA memcpy Device-to-Host]\n",
      "    536.871      1   536.871   536.871   536.871   536.871        0.000  [CUDA memcpy Host-to-Device]\n",
      "\n",
      "Generated:\n",
      "    /gpfs/home/scortinhal/CHPS0904/task/06_Kernels_in_Streams/kernel_baseline_cipher/baseline-report.nsys-rep\n",
      "    /gpfs/home/scortinhal/CHPS0904/task/06_Kernels_in_Streams/kernel_baseline_cipher/baseline-report.sqlite\n",
      "TIMING: 40.5898 ms (allocate memory)\n",
      "TIMING: 397226 ms (encrypt data on CPU)\n",
      "TIMING: 1.47894 ms (copy data from CPU to GPU)\n",
      "TIMING: 33.8325 ms (decrypt data on GPU)\n",
      "TIMING: 3.45536 ms (copy data from GPU to CPU)\n",
      "TIMING: 47.615 ms (total time on GPU)\n",
      "STATUS: test passed\n",
      "TIMING: 53.7659 ms (checking result on CPU)\n",
      "TIMING: 10.5791 ms (free memory)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Affiche le répertoire courant pour vérifier le point de départ\n",
    "pwd\n",
    "\n",
    "cd kernel_baseline_cipher\n",
    "\n",
    "module load cuda/12.6\n",
    "\n",
    "make profile\n",
    "\n",
    "./baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Next</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you can launch kernels in non-default streams, you will in the next section launch memory transfers in non-default streams.\n",
    "\n",
    "Please continue to the next section: [*Memcpy in Streams*](../07_Memcpy_in_Streams/Memcpy_in_Streams.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Optional Further Study</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are for students with time and interest to do additional study on topics related to this workshop.\n",
    "\n",
    "* In scenarios where a single kernel is unable to saturate the device, you might consider using streams to [launch multiple kernels simultaneously](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#concurrent-kernel-execution).\n",
    "* For full coverage of of CUDA stream management functions, see [Stream Management](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html) in the CUDA Runtime API docs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
