{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#65AE11;\">Exercise: Copy Compute Overlap with Multiple GPUs</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will refactor the baseline cipher application to perform copy/compute overlap while utilizing multiple GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Objectives</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the time you complete this section you will:\n",
    "\n",
    "* Be able to perform copy/compute overlap on multiple GPUs\n",
    "* Observe copy/compute overlap on multiple GPUs in the Nsight Systems timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Exercise Instructions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the techniques from the previous section to perform copy/compute overlap on multiple GPUs in [mgpu_stream.cu](mgpu_stream_cipher/mgpu_stream.cu).\n",
    "\n",
    "Use the terminal to run `make mgpu_stream` to compile the program, and then `./mgpu_stream` to run it. You will see the timing outputs and check for correctness. See the [Makefile](mgpu_stream_cipher/Makefile) for details.\n",
    "\n",
    "**As a goal try to get the total amount of time on the GPUs (including memory transfers) below 30ms.**\n",
    "\n",
    "Use the terminal to run `make profile` to generate a report file that will be named `mgpu-stream-report.qdrep`, and which you can open in Nsight Systems. See the [Makefile](mgpu_stream_cipher/Makefile) for details.\n",
    "\n",
    "The following screenshot shows the application performing copy/compute overlap with multiple GPUs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![multiple gpu copy/compute](images/mgpu_copy_compute.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Exercise Hints</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like, expand the following hints to guide your work:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* All your work should be within the `main` function\n",
    "* As you work, edit the use of the timer instances, including their message strings, to reflect changes you make to the application\n",
    "* Create variables to define each GPU's chunk of data, and, each stream on each GPU's chunk of data\n",
    "* Create and store all streams in a 2D array, with each row containing one GPU's streams\n",
    "* Store pointers for each GPU's memory in an array\n",
    "* Using robust indexing techniques, allocate a GPU's chunk of data for each GPU\n",
    "* For each stream, on each GPU, perform async HtoD transfer, kernel launch, and async DtoH transfer, synchronizing streams as needed\n",
    "* `make clean` will delete all binaries and report files\n",
    "* You can edit the [*Makefile*](mgpu_cipher/Makefile) as you wish, for example, to change the name of generated binaries or report files. You can of course also enter the commands found in the *Makefile* directly into the terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ma version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/home/scortinhal/CHPS0904/task/13_Exercise_MGPU_Streams\n",
      "nvcc -arch=sm_70 -O3 -Xcompiler=\"-march=native -fopenmp\" mgpu_streams.cu -o mgpu_streams\n",
      "nsys profile --stats=true --force-overwrite=true -o mgpu_streams-report ./mgpu_streams\n",
      "GPUs disponibles: 2\n",
      "TIMING: 19.5001 ms (Temps H2D+compute+D2H)\n",
      "STATUS: PASSED\n",
      "TIMING: 15769.3 ms (Temps total)\n",
      "Collecting data...\n",
      "Generating '/tmp/nsys-report-823b.qdstrm'\n",
      "[1/8] [========================100%] mgpu_streams-report.nsys-rep\n",
      "[2/8] [========================100%] mgpu_streams-report.sqlite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SKIPPED: /gpfs/home/scortinhal/CHPS0904/task/13_Exercise_MGPU_Streams/kernel_streams_cipher/mgpu_streams-report.sqlite does not contain NV Tools Extension (NVTX) data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/8] Executing 'nvtx_sum' stats report\n",
      "[4/8] Executing 'osrt_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls   Avg (ns)     Med (ns)    Min (ns)  Max (ns)   StdDev (ns)           Name         \n",
      " --------  ---------------  ---------  -----------  -----------  --------  ---------  -----------  ----------------------\n",
      "     52.6      16181200032        182   88907692.5  100111904.0      1568  161862336   30942778.5  poll                  \n",
      "     45.7      14038515040         63  222833572.1    4431680.0     34304  681210048  265426929.1  futex                 \n",
      "      1.3        414149312       1466     282502.9      12720.0      1024   81389536    2446659.9  ioctl                 \n",
      "      0.3         93550976        129     725201.4       5248.0      1024   92849472    8174457.9  open64                \n",
      "      0.0          6701440         18     372302.2     336496.0    321728     692544      92742.0  pthread_create        \n",
      "      0.0          5026688         67      75025.2       9952.0      2752    4287648     522471.5  mmap                  \n",
      "      0.0          1112128         92      12088.3      11296.0      5888      26464       3465.4  mmap64                \n",
      "      0.0           740640         20      37032.0      24128.0     15552     148480      34709.8  sem_timedwait         \n",
      "      0.0           720256         82       8783.6       5296.0      2656      85056      11622.6  fopen                 \n",
      "      0.0           164576         38       4330.9       1600.0      1120      64448      10457.9  fclose                \n",
      "      0.0            77504          5      15500.8       4512.0      3296      55488      22524.3  fgets                 \n",
      "      0.0            69664          4      17416.0      14304.0     11040      30016       8580.6  fread                 \n",
      "      0.0            61984         21       2951.6       3040.0      1376       4416       1000.8  write                 \n",
      "      0.0            54752          1      54752.0      54752.0     54752      54752          0.0  pthread_cond_wait     \n",
      "      0.0            50944          9       5660.4       5408.0      1632      13440       3756.5  open                  \n",
      "      0.0            35872          5       7174.4       1504.0      1024      26208      10839.1  fcntl                 \n",
      "      0.0            35072          7       5010.3       4960.0      1248       9600       2883.6  munmap                \n",
      "      0.0            29408         11       2673.5       1824.0      1024       8192       2190.4  read                  \n",
      "      0.0            28256          4       7064.0       4464.0      3808      15520       5649.2  fopen64               \n",
      "      0.0            26304          3       8768.0       9216.0      3904      13184       4656.2  pipe2                 \n",
      "      0.0            20224          2      10112.0      10112.0      6208      14016       5521.1  fflush                \n",
      "      0.0            19520          2       9760.0       9760.0      5888      13632       5475.8  socket                \n",
      "      0.0            14400          4       3600.0       2944.0      1632       6880       2277.9  fwrite                \n",
      "      0.0            12992          1      12992.0      12992.0     12992      12992          0.0  connect               \n",
      "      0.0             4352          1       4352.0       4352.0      4352       4352          0.0  bind                  \n",
      "      0.0             2816          1       2816.0       2816.0      2816       2816          0.0  pthread_cond_broadcast\n",
      "\n",
      "[5/8] Executing 'cuda_api_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls   Avg (ns)    Med (ns)   Min (ns)  Max (ns)  StdDev (ns)           Name         \n",
      " --------  ---------------  ---------  ----------  ----------  --------  --------  -----------  ----------------------\n",
      "     44.1         23750144          1  23750144.0  23750144.0  23750144  23750144          0.0  cudaHostAlloc         \n",
      "     27.2         14651136         64    228924.0    255536.0      1536    461344     224659.4  cudaStreamSynchronize \n",
      "     12.3          6618560          1   6618560.0   6618560.0   6618560   6618560          0.0  cudaFreeHost          \n",
      "      8.3          4466240         64     69785.0      3440.0      2848   3194272     417837.8  cudaLaunchKernel      \n",
      "      2.9          1552800         64     24262.5      3136.0      2048    109344      36513.4  cudaStreamCreate      \n",
      "      2.6          1425632          2    712816.0    712816.0    664032    761600      68991.0  cudaMalloc            \n",
      "      1.2           660320          2    330160.0    330160.0    296032    364288      48264.3  cudaFree              \n",
      "      0.6           319040         64      4985.0      4480.0      3936     19584       2108.6  cudaStreamDestroy     \n",
      "      0.6           312224        128      2439.3      1856.0      1376     34368       3077.5  cudaMemcpyAsync       \n",
      "      0.1            44000          4     11000.0      9216.0      4064     21504       7737.4  cudaEventRecord       \n",
      "      0.0            14432          4      3608.0      2848.0       608      8128       3679.7  cudaEventCreate       \n",
      "      0.0            12480          2      6240.0      6240.0      5248      7232       1402.9  cudaEventSynchronize  \n",
      "      0.0             2208          4       552.0       512.0       224       960        313.9  cudaEventDestroy      \n",
      "      0.0             2176          1      2176.0      2176.0      2176      2176          0.0  cuModuleGetLoadingMode\n",
      "\n",
      "[6/8] Executing 'cuda_gpu_kern_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)                             Name                           \n",
      " --------  ---------------  ---------  ---------  ---------  --------  --------  -----------  ----------------------------------------------------------\n",
      "    100.0        128080855         64  2001263.4  2101968.0    561856   2156800     336201.5  decrypt_gpu(unsigned long *, unsigned long, unsigned long)\n",
      "\n",
      "[7/8] Executing 'cuda_gpu_mem_time_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)           Operation          \n",
      " --------  ---------------  -----  --------  --------  --------  --------  -----------  ----------------------------\n",
      "     53.1          4722015     64   73781.5   73760.0     50752     97376      22939.8  [CUDA memcpy Device-to-Host]\n",
      "     46.9          4177248     64   65269.5   83664.0     23008    116000      36249.8  [CUDA memcpy Host-to-Device]\n",
      "\n",
      "[8/8] Executing 'cuda_gpu_mem_size_sum' stats report\n",
      "\n",
      " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)           Operation          \n",
      " ----------  -----  --------  --------  --------  --------  -----------  ----------------------------\n",
      "    536.871     64     8.389     8.389     8.389     8.389        0.000  [CUDA memcpy Device-to-Host]\n",
      "    536.871     64     8.389     8.389     8.389     8.389        0.000  [CUDA memcpy Host-to-Device]\n",
      "\n",
      "Generated:\n",
      "    /gpfs/home/scortinhal/CHPS0904/task/13_Exercise_MGPU_Streams/kernel_streams_cipher/mgpu_streams-report.nsys-rep\n",
      "    /gpfs/home/scortinhal/CHPS0904/task/13_Exercise_MGPU_Streams/kernel_streams_cipher/mgpu_streams-report.sqlite\n",
      "GPUs disponibles: 2\n",
      "TIMING: 19.6114 ms (Temps H2D+compute+D2H)\n",
      "STATUS: PASSED\n",
      "TIMING: 14981.1 ms (Temps total)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Affiche le répertoire courant pour vérifier le point de départ\n",
    "pwd\n",
    "\n",
    "cd kernel_streams_cipher\n",
    "\n",
    "module load cuda/12.6\n",
    "\n",
    "make profile\n",
    "\n",
    "./mgpu_streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Exercise Solution</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you complete your work, or if you get stuck, refer to [the solution](mgpu_stream_cipher/mgpu_stream_solution.cu). If you wish, you can compile the solution with `make mgpu_stream_solution`, and/or generate a report file for viewing in Nsight Systems with `make profile_solution`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Next</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on the successful refactor and acceleration of the cipher application. Next, you will do a quick overview of everything you learned in this workshop, and will be asked to take the course survey before attempting the workshop assessment.\n",
    "\n",
    "Please continue to the next section: [*Workshop Overview*](../14_Overview/Overview.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
