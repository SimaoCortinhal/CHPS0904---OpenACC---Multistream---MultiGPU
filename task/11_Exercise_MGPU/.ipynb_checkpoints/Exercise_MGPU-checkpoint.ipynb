{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#65AE11;\">Exercise: Use Multiple GPUs</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will refactor the baseline cipher application to utilize multiple GPUs.\n",
    "\n",
    "*Please note, you will be working with the baseline cipher application that **does not use multiple non-default streams**. For the sake of learning you will be focusing on multiple GPU usage in this section, before combining multiple GPUs with multiple non-default streams in the next section.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Objectives</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the time you complete this section you will:\n",
    "\n",
    "* Be able to utilize multiple GPUs in a CUDA C++ application\n",
    "* Observe multiple GPU usage in the Nsight Systems timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Exercise Instructions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the techniques from the previous section to utilize multiple GPUs in [mgpu.cu](mgpu_cipher/mgpu.cu).\n",
    "\n",
    "Use the terminal to run `make mgpu` to compile the program, and then `./mgpu` to run it. You will see the timing outputs and check for correctness. See the [Makefile](mgpu_cipher/Makefile) for details.\n",
    "\n",
    "**As a goal try to get the amount of time spent decrypting on the GPUs (not including memory transfers) below 20ms.**\n",
    "\n",
    "Use the terminal to run `make profile` to generate a report file that will be named `mgpu-report.qdrep`, and which you can open in Nsight Systems. See the [Makefile](mgpu_cipher/Makefile) for details.\n",
    "\n",
    "The following screenshot shows the application utilizing multiple GPUs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![multiple gpus](images/multiple_gpus.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Exercise Hints</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like, expand the following hints to guide your work:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* All your work should be within the `main` function\n",
    "* Store the number of GPUs available in a variable for later use\n",
    "* Using the number of entries and the number of GPUs, define a chunk size for each stream's work. Remember to use the round-up division helper function `sdiv` for the reasons discussed in a previous section\n",
    "* Create an array that contains pointers for the memory that will be allocated on each GPU\n",
    "* Allocate a chunk's worth of data for each GPU\n",
    "* Copy the correct chunk of data to each GPU\n",
    "* For each GPU, decrypt its chunk of data\n",
    "* Copy each GPU's chunk of data back to the host\n",
    "* You may wish to edit the use of the timer instances, including their message strings, to reflect changes you make to the application\n",
    "* `make clean` will delete all binaries and report files\n",
    "* You can edit the [*Makefile*](mgpu_cipher/Makefile) as you wish, for example, to change the name of generated binaries or report files. You can of course also enter the commands found in the *Makefile* directly into the terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ma version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/home/scortinhal/CHPS0904/task/11_Exercise_MGPU\n",
      "nsys profile --stats=true --force-overwrite=true -o mgpu-report ./mgpu\n",
      "Nombre de GPUs disponibles : 4\n",
      "TIMING: 14.4115 ms (Temps de décryptage kernel sur GPUs)\n",
      "STATUS: test passed\n",
      "Collecting data...\n",
      "Generating '/tmp/nsys-report-7e68.qdstrm'\n",
      "[1/8] [========================100%] mgpu-report.nsys-rep\n",
      "[2/8] [========================100%] mgpu-report.sqlite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SKIPPED: /gpfs/home/scortinhal/CHPS0904/task/11_Exercise_MGPU/kernel_streams_cipher/mgpu-report.sqlite does not contain NV Tools Extension (NVTX) data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/8] Executing 'nvtx_sum' stats report\n",
      "[4/8] Executing 'osrt_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls   Avg (ns)    Med (ns)    Min (ns)  Max (ns)   StdDev (ns)           Name         \n",
      " --------  ---------------  ---------  ----------  -----------  --------  ---------  -----------  ----------------------\n",
      "     99.7     418823224224       4216  99341372.0  100117632.0      1984  711430560   13273780.0  poll                  \n",
      "      0.3       1301667360       2862    454810.4      16992.0      1056  492788704    9333322.3  ioctl                 \n",
      "      0.0         15158784         42    360923.4      36464.0      1088   12461312    1915383.2  write                 \n",
      "      0.0         13157664          1  13157664.0   13157664.0  13157664   13157664          0.0  pthread_cond_wait     \n",
      "      0.0          9091776        128     71029.5      15824.0      2432    6917856     609978.0  mmap                  \n",
      "      0.0          8951200          1   8951200.0    8951200.0   8951200    8951200          0.0  pthread_cond_broadcast\n",
      "      0.0          6092608          3   2030869.3    2042848.0   1551520    2498240     473473.7  fflush                \n",
      "      0.0          3548704        184     19286.4      18240.0      6208     145920      10878.8  mmap64                \n",
      "      0.0          2790784          5    558156.8     572448.0    445664     679008     105227.3  pthread_create        \n",
      "      0.0          2260544        251      9006.2       7776.0      2432     205312      12870.4  open64                \n",
      "      0.0          1023424         98     10443.1       5504.0      2528     121472      15284.5  fopen                 \n",
      "      0.0           403200         65      6203.1       1632.0      1024     193344      23945.4  fclose                \n",
      "      0.0           124608          5     24921.6      11264.0      5824      85760      34264.0  fgets                 \n",
      "      0.0           101536         13      7810.5       8352.0      2016      12832       4476.4  munmap                \n",
      "      0.0            95552          4     23888.0      21520.0     11904      40608      12742.9  fread                 \n",
      "      0.0            82368         23      3581.2       1152.0      1024      49280      10035.8  fcntl                 \n",
      "      0.0            77056         35      2201.6       1664.0      1024      10944       2057.2  read                  \n",
      "      0.0            71360          9      7928.9       8000.0      1856      18144       5067.3  open                  \n",
      "      0.0            30144          3     10048.0       9312.0      3264      17568       7180.3  pipe2                 \n",
      "      0.0            27520          2     13760.0      13760.0     10400      17120       4751.8  socket                \n",
      "      0.0            21024          6      3504.0       3040.0      1920       6336       1506.6  fwrite                \n",
      "      0.0            19616          4      4904.0       3184.0      2720      10528       3756.3  fopen64               \n",
      "      0.0            19200          1     19200.0      19200.0     19200      19200          0.0  connect               \n",
      "      0.0             5280          2      2640.0       2640.0      2528       2752        158.4  futex                 \n",
      "      0.0             2720          1      2720.0       2720.0      2720       2720          0.0  bind                  \n",
      "\n",
      "[5/8] Executing 'cuda_api_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls   Avg (ns)    Med (ns)   Min (ns)  Max (ns)  StdDev (ns)           Name         \n",
      " --------  ---------------  ---------  ----------  ----------  --------  --------  -----------  ----------------------\n",
      "     54.4         33956320          1  33956320.0  33956320.0  33956320  33956320          0.0  cudaHostAlloc         \n",
      "     16.2         10101920          1  10101920.0  10101920.0  10101920  10101920          0.0  cudaFreeHost          \n",
      "     14.1          8806272          4   2201568.0   1896912.0   1568928   3443520     877779.5  cudaDeviceSynchronize \n",
      "      8.7          5439584          4   1359896.0   1555472.0    756896   1571744     402110.1  cudaLaunchKernel      \n",
      "      4.0          2481888          4    620472.0    606896.0    583584    684512      44155.6  cudaMalloc            \n",
      "      2.2          1384768          4    346192.0    331968.0    303392    417440      50657.4  cudaFree              \n",
      "      0.2           129184          8     16148.0      8864.0      4544     48672      16244.0  cudaMemcpyAsync       \n",
      "      0.1            50176          2     25088.0     25088.0      6720     43456      25976.3  cudaEventRecord       \n",
      "      0.0            22720          4      5680.0      5584.0       832     10720       4149.4  cudaEventCreate       \n",
      "      0.0             7968          1      7968.0      7968.0      7968      7968          0.0  cudaEventSynchronize  \n",
      "      0.0             4960          4      1240.0       800.0       544      2816       1060.5  cudaEventDestroy      \n",
      "      0.0             1408          1      1408.0      1408.0      1408      1408          0.0  cuModuleGetLoadingMode\n",
      "\n",
      "[6/8] Executing 'cuda_gpu_kern_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)                             Name                           \n",
      " --------  ---------------  ---------  ---------  ---------  --------  --------  -----------  ----------------------------------------------------------\n",
      "    100.0         29202560          4  7300640.0  7282512.0   7271840   7365696      43682.2  decrypt_gpu(unsigned long *, unsigned long, unsigned long)\n",
      "\n",
      "[7/8] Executing 'cuda_gpu_mem_time_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Count  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)           Operation          \n",
      " --------  ---------------  -----  ---------  ---------  --------  --------  -----------  ----------------------------\n",
      "     52.5          5411552      4  1352888.0  1515232.0    859328   1521760     329054.6  [CUDA memcpy Device-to-Host]\n",
      "     47.5          4892704      4  1223176.0  1514064.0    349984   1514592     582128.1  [CUDA memcpy Host-to-Device]\n",
      "\n",
      "[8/8] Executing 'cuda_gpu_mem_size_sum' stats report\n",
      "\n",
      " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)           Operation          \n",
      " ----------  -----  --------  --------  --------  --------  -----------  ----------------------------\n",
      "    536.871      4   134.218   134.218   134.218   134.218        0.000  [CUDA memcpy Device-to-Host]\n",
      "    536.871      4   134.218   134.218   134.218   134.218        0.000  [CUDA memcpy Host-to-Device]\n",
      "\n",
      "Generated:\n",
      "    /gpfs/home/scortinhal/CHPS0904/task/11_Exercise_MGPU/kernel_streams_cipher/mgpu-report.nsys-rep\n",
      "    /gpfs/home/scortinhal/CHPS0904/task/11_Exercise_MGPU/kernel_streams_cipher/mgpu-report.sqlite\n",
      "Process is interrupted.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Affiche le répertoire courant pour vérifier le point de départ\n",
    "pwd\n",
    "\n",
    "cd kernel_streams_cipher\n",
    "\n",
    "module load cuda/12.6\n",
    "\n",
    "make profile\n",
    "\n",
    "./mgpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Exercise Solution</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you complete your work, or if you get stuck, refer to [the solution](mgpu_cipher/mgpu_solution.cu). If you wish, you can compile the solution with `make mgpu_solution`, and/or generate a report file for viewing in Nsight Systems with `make profile_solution`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Check for Understanding</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please answer the following to confirm you've learned the main objectives of this section. You can display the answers for each question by clicking on the \"...\" cells below the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the visual profiler, we can see that overlapping kernel execution. Why is this so?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "We are using multiple GPUs to execute chunks of the work required by our application, all of which can perform work at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the visual profiler image of the solution code, above, we can see that there is no overlap of memory transfers. Why is this so?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "The solution code is using neither non-default streams, nor, `cudaMemcpyAsync` for memory copies. They are, therefore, blocking operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#65AE11;\">Next</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now know how to perform copy/compute overlap, and, how to perform work on multiple GPUs. In the next section you will learn about streams on multiple GPUs, and how to perform copy/compute overlap on multiple GPUs.\n",
    "\n",
    "Please continue to the next section: [*MGPU Streams*](../12_MGPU_Streams/MGPU_Streams.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
